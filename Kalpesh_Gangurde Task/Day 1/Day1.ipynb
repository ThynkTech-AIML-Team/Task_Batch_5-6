{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d66c21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Day 1 â€“ NLP Internship Tasks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a02b3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Task 1: Sentiment Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c942ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: Positive\n"
     ]
    }
   ],
   "source": [
    "positive_words = [\"good\", \"great\", \"amazing\", \"fantastic\", \"excellent\"]\n",
    "negative_words = [\"bad\", \"worst\", \"boring\", \"terrible\", \"poor\"]\n",
    "\n",
    "review = \"The cricket match was amazing and fantastic\"\n",
    "\n",
    "score = 0\n",
    "for word in review.lower().split():\n",
    "    if word in positive_words:\n",
    "        score += 1\n",
    "    elif word in negative_words:\n",
    "        score -= 1\n",
    "\n",
    "if score > 0:\n",
    "    print(\"Sentiment: Positive\")\n",
    "else:\n",
    "    print(\"Sentiment: Negative\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0fe8e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Task 1: Text Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7624fc29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cricket is one of the most popular sports in the world, especially in India. Teamwork plays a major role in winning cricket matches.\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "Cricket is one of the most popular sports in the world, especially in India.\n",
    "The game requires physical fitness, mental strength, and smart strategy.\n",
    "Batsmen focus on scoring runs while bowlers aim to take wickets.\n",
    "Fielding helps in saving runs and building pressure.\n",
    "Teamwork plays a major role in winning cricket matches.\n",
    "\"\"\"\n",
    "\n",
    "sentences = [s.strip() for s in text.split('.') if s.strip()]\n",
    "summary = sentences[0] + \". \" + sentences[-1] + \".\"\n",
    "\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46f80c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Task 2: Text Data Basics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3eb378c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Cricket is one of the most popular sports in India.\n",
    "It requires physical fitness, mental strength, and discipline.\n",
    "Teamwork and consistency help teams win matches.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1a119e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_analysis(paragraph):\n",
    "    sentences = [s.strip() for s in paragraph.split('.') if s.strip()]\n",
    "    tokens = paragraph.replace('.', '').split()\n",
    "    return sentences, tokens, len(sentences), len(tokens), 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f28e4c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cricket is one of the most popular sports in India', 'It requires physical fitness, mental strength, and discipline', 'Teamwork and consistency help teams win matches']\n",
      "['Cricket', 'is', 'one', 'of', 'the', 'most', 'popular', 'sports', 'in', 'India', 'It', 'requires', 'physical', 'fitness,', 'mental', 'strength,', 'and', 'discipline', 'Teamwork', 'and', 'consistency', 'help', 'teams', 'win', 'matches']\n",
      "3\n",
      "25\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "sentences, tokens, s_count, t_count, p_count = text_analysis(text)\n",
    "\n",
    "print(sentences)\n",
    "print(tokens)\n",
    "print(s_count)\n",
    "print(t_count)\n",
    "print(p_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b69671ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Task 3: Text Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "137e2d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Kalpesh\n",
      "[nltk_data]     Gangurde\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2adb67d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cricket', 'is', 'amazing', '!', 'Players', 'train', 'hard', 'every', 'day', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "text = \"Cricket is amazing! Players train hard every day.\"\n",
    "tokens = word_tokenize(text)\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7062e066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cricket', 'amazing', '!', 'Players', 'train', 'hard', 'every', 'day', '.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Kalpesh\n",
      "[nltk_data]     Gangurde\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "filtered = [w for w in tokens if w.lower() not in stopwords.words(\"english\")]\n",
    "print(filtered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7a80529",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Kalpesh\n",
      "[nltk_data]     Gangurde\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "studi study\n",
      "studi studying\n",
      "studi studied\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "\n",
    "words = [\"studies\", \"studying\", \"studied\"]\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "for w in words:\n",
    "    print(stemmer.stem(w), lemmatizer.lemmatize(w))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664d9023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great match   \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"Great match!!!  #Cricket @player123\"\n",
    "clean_text = re.sub(r\"[@#]\\w+|[^\\w\\s]\", \"\", text)\n",
    "print(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5d0430d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cricket is fun and exciting\n"
     ]
    }
   ],
   "source": [
    "text = \"Cricket Is FUN   And   Exciting\"\n",
    "print(\" \".join(text.lower().split()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "501180e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test@gmail.com', 'admin@yahoo.com']\n",
      "Contact test@gmail.com or admin@yahoo.com Call \n",
      "Contact test@gmail.com or admin@yahoo.com Call 12345\n"
     ]
    }
   ],
   "source": [
    "text = \"Contact test@gmail.com or admin@yahoo.com Call 12345\"\n",
    "\n",
    "emails = re.findall(r'\\S+@\\S+', text)\n",
    "no_numbers = re.sub(r'\\d+', '', text)\n",
    "clean_spaces = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "print(emails)\n",
    "print(no_numbers)\n",
    "print(clean_spaces)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "acfa4ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Task 4: Bag-of-Words and TF-IDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "70827821",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"Cricket is a popular sport\",\n",
    "    \"Cricket players train hard\",\n",
    "    \"The sport requires teamwork\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34d9d652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cricket' 'hard' 'is' 'players' 'popular' 'requires' 'sport' 'teamwork'\n",
      " 'the' 'train']\n",
      "[[1 0 1 0 1 0 1 0 0 0]\n",
      " [1 1 0 1 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 1 1 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "bow = CountVectorizer()\n",
    "bow_matrix = bow.fit_transform(sentences)\n",
    "\n",
    "print(bow.get_feature_names_out())\n",
    "print(bow_matrix.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8dcbfbf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cricket' 'hard' 'is' 'players' 'popular' 'requires' 'sport' 'teamwork'\n",
      " 'the' 'train']\n",
      "[[0.42804604 0.         0.5628291  0.         0.5628291  0.\n",
      "  0.42804604 0.         0.         0.        ]\n",
      " [0.40204024 0.52863461 0.         0.52863461 0.         0.\n",
      "  0.         0.         0.         0.52863461]\n",
      " [0.         0.         0.         0.         0.         0.52863461\n",
      "  0.40204024 0.52863461 0.52863461 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf.fit_transform(sentences)\n",
    "\n",
    "print(tfidf.get_feature_names_out())\n",
    "print(tfidf_matrix.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72df94e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

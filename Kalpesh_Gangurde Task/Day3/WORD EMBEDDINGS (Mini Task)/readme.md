Task: Word Embeddings Mini Task

Model Used:
- Pretrained Word2Vec (Google News)

Libraries:
- gensim
- scikit-learn
- matplotlib

Tasks Performed:
- Loaded pretrained Word2Vec model
- Found similar words (example: king â†’ queen)
- Performed word analogy (king - man + woman)
- Visualized word embeddings using PCA (2D)

Result:
- Semantically similar words are placed closer in vector space
- Word analogies successfully capture relationships between words

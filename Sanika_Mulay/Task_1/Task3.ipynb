{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4870ba00-959d-4957-9299-c0c6f5bc34c2",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a8716c4-0e87-4db3-88d5-caf5d6d51b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in c:\\programdata\\anaconda3\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: spacy in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (3.8.11)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (8.2.1)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (2025.9.1)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from spacy) (1.0.15)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from spacy) (2.0.13)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from spacy) (8.3.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from spacy) (2.5.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from spacy) (0.4.3)\n",
      "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from spacy) (0.24.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (2.3.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (2.32.5)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (2.12.4)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (80.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (25.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.41.5)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.11.12)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.3)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm->nltk) (0.4.6)\n",
      "Requirement already satisfied: typer>=0.24.0 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from typer-slim<1.0.0,>=0.3.0->spacy) (0.24.0)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from weasel<0.5.0,>=0.4.2->spacy) (0.23.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from weasel<0.5.0,>=0.4.2->spacy) (7.5.0)\n",
      "Requirement already satisfied: wrapt in c:\\programdata\\anaconda3\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy) (1.17.0)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from typer>=0.24.0->typer-slim<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=12.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from typer>=0.24.0->typer-slim<1.0.0,>=0.3.0->spacy) (14.2.0)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from typer>=0.24.0->typer-slim<1.0.0,>=0.3.0->spacy) (0.0.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim<1.0.0,>=0.3.0->spacy) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim<1.0.0,>=0.3.0->spacy) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=12.3.0->typer>=0.24.0->typer-slim<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->spacy) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37a062c5-d72d-4183-90a4-c8703431752b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.3/12.8 MB ? eta -:--:--\n",
      "     -- ------------------------------------- 0.8/12.8 MB 3.7 MB/s eta 0:00:04\n",
      "     ---- ----------------------------------- 1.6/12.8 MB 3.2 MB/s eta 0:00:04\n",
      "     ------- -------------------------------- 2.4/12.8 MB 3.3 MB/s eta 0:00:04\n",
      "     ---------- ----------------------------- 3.4/12.8 MB 3.9 MB/s eta 0:00:03\n",
      "     ------------- -------------------------- 4.2/12.8 MB 3.7 MB/s eta 0:00:03\n",
      "     --------------- ------------------------ 5.0/12.8 MB 3.7 MB/s eta 0:00:03\n",
      "     ------------------- -------------------- 6.3/12.8 MB 4.1 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 7.3/12.8 MB 4.2 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 8.4/12.8 MB 4.3 MB/s eta 0:00:02\n",
      "     ---------------------------- ----------- 9.2/12.8 MB 4.3 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 10.7/12.8 MB 4.5 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.3/12.8 MB 4.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 4.7 MB/s  0:00:02\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4461f9-14ce-4cc3-9697-3f2f4a7c4929",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca88b486-02e2-4fd5-97c7-53a08eebfd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "!{sys.executable} -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda6f934-c2bf-4fcf-bfe9-657ab6e8a5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "print(\"Model loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48387651-783f-48c7-93cf-fcb12bd710bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ed92975-213d-4c67-b3b6-7a6f4c753a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ADMIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8a330bb-3fd2-45da-a02f-5e04bf56356b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Hello! This is Sanika's NLP assignment. Let's compare tokenizers.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b08fd79a-1b87-4e59-bbf2-5d649bc39059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK Tokens:\n",
      "['Hello', '!', 'This', 'is', 'Sanika', \"'s\", 'NLP', 'assignment', '.']\n"
     ]
    }
   ],
   "source": [
    "# NLTK Tokenizer\n",
    "nltk_tokens = word_tokenize(text)\n",
    "print(\"NLTK Tokens:\")\n",
    "print(nltk_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a210c2b-cc49-4ea2-bb39-4b351215005f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spaCy Tokenizer\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b626e655-13ec-4f30-be8c-03607e95b622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "spaCy Tokens:\n",
      "['Hello', '!', 'This', 'is', 'Sanika', \"'s\", 'NLP', 'assignment', '.']\n"
     ]
    }
   ],
   "source": [
    "spacy_tokens = [token.text for token in doc]\n",
    "print(\"\\nspaCy Tokens:\")\n",
    "print(spacy_tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b33d40-8892-4738-b1ed-a7968e3f6e43",
   "metadata": {},
   "source": [
    "## Stopwords Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b40cf16-bb55-45b4-8498-7c72207ea9aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: ['This', 'is', 'a', 'simple', 'example', 'to', 'demonstrate', 'stopwords', 'removal', 'in', 'NLP', '.']\n",
      "After: ['simple', 'example', 'demonstrate', 'stopwords', 'removal', 'NLP', '.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ADMIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "text = \"This is a simple example to demonstrate stopwords removal in NLP.\"\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "tokens = word_tokenize(text)\n",
    "\n",
    "filtered_text = [word for word in tokens if word.lower() not in stop_words]\n",
    "\n",
    "print(\"Before:\", tokens)\n",
    "print(\"After:\", filtered_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b19bad4-8a25-4247-930e-47dd8ead8ac7",
   "metadata": {},
   "source": [
    "## Lemmatization and stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0f85dbd-68ce-4dba-a277-b1275f1848f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ADMIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: ['The', 'students', 'are', 'studying', 'and', 'writing', 'studies', '.']\n",
      "Stemmed: ['the', 'student', 'are', 'studi', 'and', 'write', 'studi', '.']\n",
      "Lemmatized: ['The', 'student', 'are', 'studying', 'and', 'writing', 'study', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "\n",
    "text = \"The students are studying and writing studies.\"\n",
    "\n",
    "tokens = word_tokenize(text)\n",
    "\n",
    "# Stemming\n",
    "ps = PorterStemmer()\n",
    "stemmed = [ps.stem(word) for word in tokens]\n",
    "\n",
    "# Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "print(\"Original:\", tokens)\n",
    "print(\"Stemmed:\", stemmed)\n",
    "print(\"Lemmatized:\", lemmatized)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9404b1af-47ad-4947-9330-375cc3c1e6cd",
   "metadata": {},
   "source": [
    "## Handling Punctuation, Special Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8385f8b2-dc13-49e9-9c51-b900ecc1beb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Hey @sanika!!! This is amazing  #NLP #AI 2026!!!\n",
      "Cleaned: Hey  This is amazing    2026\n"
     ]
    }
   ],
   "source": [
    "#Clean text with regex + emojii library\n",
    "import re\n",
    "import emoji\n",
    "\n",
    "text = \"Hey @sanika!!! This is amazing  #NLP #AI 2026!!!\"\n",
    "\n",
    "print(\"Original:\", text)\n",
    "\n",
    "# Remove mentions & hashtags\n",
    "text = re.sub(r'@\\w+', '', text)\n",
    "text = re.sub(r'#\\w+', '', text)\n",
    "\n",
    "# Remove punctuation\n",
    "text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "# Remove emojis\n",
    "text = emoji.replace_emoji(text, replace='')\n",
    "\n",
    "print(\"Cleaned:\", text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "706352be-f94d-4b64-9759-23d111d23098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting emoji\n",
      "  Downloading emoji-2.15.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Downloading emoji-2.15.0-py3-none-any.whl (608 kB)\n",
      "   ---------------------------------------- 0.0/608.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/608.4 kB ? eta -:--:--\n",
      "   ----------------- ---------------------- 262.1/608.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 608.4/608.4 kB 1.9 MB/s  0:00:00\n",
      "Installing collected packages: emoji\n",
      "Successfully installed emoji-2.15.0\n"
     ]
    }
   ],
   "source": [
    "!pip install emoji"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309759d4-b72e-4fc2-997b-acc12e30f368",
   "metadata": {},
   "source": [
    "## Lowercasing and Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5a8a190a-725a-44be-9c4e-a33ffe7fefd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is mixed case text.\n"
     ]
    }
   ],
   "source": [
    "text = \"   This   Is   MIXED Case   TEXT.   \"\n",
    "\n",
    "# Lowercase\n",
    "text = text.lower()\n",
    "\n",
    "# Normalize spacing\n",
    "text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0cecab-3714-478d-9069-50496db05951",
   "metadata": {},
   "source": [
    "# Regex for Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7c3df7fb-edfc-4e00-9820-19d196c5190a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emails Found: ['sanika@gmail.com', 'thynktech@company.co.in']\n"
     ]
    }
   ],
   "source": [
    "text = \"Contact us at sanika@gmail.com or thynktech@company.co.in for details.\"\n",
    "\n",
    "emails = re.findall(r'[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+', text)\n",
    "\n",
    "print(\"Emails Found:\", emails)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd24a17-39cb-4dbb-82c4-674d19402afc",
   "metadata": {},
   "source": [
    "## Remove Numbers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a9cf552-97ee-420a-ad26-36ba1ee12e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI  will change  industries.\n"
     ]
    }
   ],
   "source": [
    "text = \"AI 2026 will change 500 industries.\"\n",
    "\n",
    "no_numbers = re.sub(r'\\d+', '', text)\n",
    "print(no_numbers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de768ddf-d5f3-42dc-ac64-2077e594ab99",
   "metadata": {},
   "source": [
    "## Replace Multiple Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9496a767-5286-433a-8548-6b8737ed5f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is too many spaces.\n"
     ]
    }
   ],
   "source": [
    "text = \"This    is    too     many   spaces.\"\n",
    "\n",
    "cleaned = re.sub(r'\\s+', ' ', text)\n",
    "print(cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75537e2-2bde-4d92-9a1e-29dabf9487b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

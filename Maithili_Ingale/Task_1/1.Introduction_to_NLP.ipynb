{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "468f922b-7936-4a31-a6eb-d3b324789c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK version: 3.9.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "print(\"NLTK version:\", nltk.__version__)\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"movie_reviews\")\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13f278bb-6d9d-4298-9a53-0686de6c72db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8225\n",
      "This movie was amazing and very inspiring. -> positive\n",
      "Worst movie ever, completely boring. -> negative\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import movie_reviews\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset\n",
    "docs, labels = [], []\n",
    "\n",
    "for fid in movie_reviews.fileids(\"pos\"):\n",
    "    docs.append(movie_reviews.raw(fid))\n",
    "    labels.append(1)\n",
    "\n",
    "for fid in movie_reviews.fileids(\"neg\"):\n",
    "    docs.append(movie_reviews.raw(fid))\n",
    "    labels.append(0)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    docs, labels, test_size=0.2, random_state=42, stratify=labels\n",
    ")\n",
    "\n",
    "# Model pipeline\n",
    "model = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(stop_words=\"english\", max_features=20000)),\n",
    "    (\"clf\", LogisticRegression(max_iter=2000))\n",
    "])\n",
    "\n",
    "# Train\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "preds = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, preds))\n",
    "\n",
    "# Test on custom text\n",
    "samples = [\n",
    "    \"This movie was amazing and very inspiring.\",\n",
    "    \"Worst movie ever, completely boring.\"\n",
    "]\n",
    "for s in samples:\n",
    "    print(s, \"->\", \"positive\" if model.predict([s])[0] == 1 else \"negative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0ad7f31-3a53-4e0d-8810-f84c14c90849",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"punkt_tab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "062cc47d-c663-4616-912f-056f96eb9a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      " Natural language processing helps computers understand human language. It is used in chatbots, sentiment analysis, translation and spam detection. Preprocessing like tokenization and cleaning improves accuracy. Machine learning models can classify and summarize text data.\n",
      "\n",
      "Summary:\n",
      " Natural language processing helps computers understand human language. Machine learning models can classify and summarize text data.\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "\n",
    "def summarize_simple(text, n_sentences=2):\n",
    "    STOP = set(stopwords.words(\"english\"))\n",
    "    sentences = sent_tokenize(text)\n",
    "    words = [w.lower() for w in word_tokenize(text) if w.isalpha()]\n",
    "    freq = Counter(w for w in words if w not in STOP)\n",
    "\n",
    "    scored = []\n",
    "    for i, s in enumerate(sentences):\n",
    "        ws = [w.lower() for w in word_tokenize(s) if w.isalpha()]\n",
    "        score = sum(freq.get(w, 0) for w in ws)\n",
    "        scored.append((score, i, s))\n",
    "\n",
    "    top = sorted(scored, reverse=True)[:n_sentences]\n",
    "    return \" \".join(s for _, _, s in sorted(top, key=lambda x: x[1]))\n",
    "\n",
    "text = (\n",
    "    \"Natural language processing helps computers understand human language. \"\n",
    "    \"It is used in chatbots, sentiment analysis, translation and spam detection. \"\n",
    "    \"Preprocessing like tokenization and cleaning improves accuracy. \"\n",
    "    \"Machine learning models can classify and summarize text data.\"\n",
    ")\n",
    "\n",
    "print(\"Original:\\n\", text)\n",
    "print(\"\\nSummary:\\n\", summarize_simple(text, n_sentences=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a80da45-b066-40c8-b350-0240b7f7eda7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook working dir: C:\\Users\\Lenovo\n",
      "Python exe: C:\\Users\\Lenovo\\AppData\\Local\\Python\\pythoncore-3.14-64\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "print(\"Notebook working dir:\", os.getcwd())\n",
    "print(\"Python exe:\", sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b902fe-e511-4a5b-b40d-f07058152cc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

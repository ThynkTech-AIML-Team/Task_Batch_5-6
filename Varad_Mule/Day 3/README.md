For Task 1, the SMS Spam Collection Dataset from the UCI Machine Learning Repository was used. This dataset contains labeled SMS messages categorized as either “spam” or “ham.” The dataset includes thousands of short text messages that represent real-world SMS communication. The objective was to build a classification model capable of identifying spam messages accurately. The text data was preprocessed by converting to lowercase, removing punctuation, and eliminating stopwords using NLTK. Feature extraction was performed using both CountVectorizer and TF-IDF Vectorizer to transform text into numerical format suitable for machine learning algorithms. Multiple models were trained, including Naive Bayes, Logistic Regression, and Support Vector Machine (SVM). The models were evaluated using accuracy, confusion matrix, and classification report. TF-IDF combined with Logistic Regression achieved the best performance, reaching approximately 98–99% accuracy.

For Task 2, pretrained GloVe (Global Vectors for Word Representation) embeddings were used to analyze semantic relationships between words. The GloVe 6B 100-dimensional embedding model was utilized for this task. This pretrained model contains word vectors trained on a large corpus of text data and captures contextual relationships between words. The task involved finding similar words using cosine similarity, performing analogy operations such as “king - man + woman,” and visualizing selected word vectors using Principal Component Analysis (PCA). The PCA visualization demonstrated that semantically related words cluster together in vector space, confirming the effectiveness of word embeddings in representing meaning.

For Task 3, a Fake News Detection System was developed using the Fake and Real News Dataset from Kaggle. This dataset consists of news articles labeled as either fake or real. The dataset contains full news article text along with corresponding class labels. The objective was to build a binary classification model to distinguish between fake and authentic news articles. After preprocessing the text data, TF-IDF vectorization was applied to convert text into numerical features. Logistic Regression and Naive Bayes models were trained and evaluated. The Logistic Regression model achieved approximately 99% accuracy with very low false positives and false negatives, as shown in the confusion matrix. The results indicate strong separation between fake and real news articles within the dataset. Additionally, an interactive prediction system was implemented, allowing users to input custom news text and receive classification results along with confidence scores.
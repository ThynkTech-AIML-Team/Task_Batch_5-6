{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c3304fd",
   "metadata": {},
   "source": [
    "# Basic Text Classification Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a824dc56",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "We will use pandas, numpy, scikit-learn, matplotlib, and nltk for data processing, modeling, and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f8cb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd29648",
   "metadata": {},
   "source": [
    "## 2. Load and Explore Dataset\n",
    "We will use the SMS Spam Collection Dataset. Let's load the data and explore its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e74ce55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and load the SMS Spam Collection Dataset\n",
    "dataset_url = 'https://raw.githubusercontent.com/justmarkham/pycon-2016-tutorial/master/data/sms.tsv'\n",
    "df = pd.read_csv(dataset_url, sep='\\t', header=None, names=['label', 'text'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088c6df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset shape and class distribution\n",
    "print('Dataset shape:', df.shape)\n",
    "print('\\nClass distribution:')\n",
    "print(df['label'].value_counts())\n",
    "df['label'].value_counts().plot(kind='bar', title='Class Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d10c640",
   "metadata": {},
   "source": [
    "## 3. Text Cleaning (Lowercase, Remove Punctuation)\n",
    "We will clean the text by converting to lowercase and removing punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ccfdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(f'[{re.escape(string.punctuation)}]', '', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "df['clean_text'] = df['text'].apply(clean_text)\n",
    "df[['text', 'clean_text']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54dc6a3d",
   "metadata": {},
   "source": [
    "## 4. Remove Stopwords\n",
    "We will remove common stopwords from the cleaned text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c489ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "def remove_stopwords(text):\n",
    "    tokens = text.split()\n",
    "    filtered = [word for word in tokens if word not in stop_words]\n",
    "    return ' '.join(filtered)\n",
    "\n",
    "df['clean_text_nostop'] = df['clean_text'].apply(remove_stopwords)\n",
    "df[['clean_text', 'clean_text_nostop']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e25793",
   "metadata": {},
   "source": [
    "## 5. Text Vectorization: CountVectorizer\n",
    "Convert the cleaned text into numerical features using CountVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cc1707",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()\n",
    "X_count = count_vect.fit_transform(df['clean_text_nostop'])\n",
    "print('CountVectorizer shape:', X_count.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac03018",
   "metadata": {},
   "source": [
    "## 6. Text Vectorization: TF-IDF\n",
    "Convert the cleaned text into numerical features using TfidfVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52360d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect = TfidfVectorizer()\n",
    "X_tfidf = tfidf_vect.fit_transform(df['clean_text_nostop'])\n",
    "print('TF-IDF shape:', X_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c73945d",
   "metadata": {},
   "source": [
    "## 7. Train-Test Split\n",
    "Split the dataset into training and testing sets for model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cd8986",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['label']\n",
    "\n",
    "Xc_train, Xc_test, yc_train, yc_test = train_test_split(X_count, y, test_size=0.2, random_state=42, stratify=y)\n",
    "Xt_train, Xt_test, yt_train, yt_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print('Train set size:', Xc_train.shape[0])\n",
    "print('Test set size:', Xc_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b4ff1e",
   "metadata": {},
   "source": [
    "## 8. Model Training and Evaluation: Naive Bayes\n",
    "Train a Naive Bayes classifier and evaluate using accuracy, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac909360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes with CountVectorizer\n",
    "nb_count = MultinomialNB()\n",
    "nb_count.fit(Xc_train, yc_train)\n",
    "yc_pred = nb_count.predict(Xc_test)\n",
    "\n",
    "print('Naive Bayes (CountVectorizer)')\n",
    "print('Accuracy:', accuracy_score(yc_test, yc_pred))\n",
    "print('Confusion Matrix:\\n', confusion_matrix(yc_test, yc_pred))\n",
    "print('Classification Report:\\n', classification_report(yc_test, yc_pred))\n",
    "\n",
    "# Naive Bayes with TF-IDF\n",
    "nb_tfidf = MultinomialNB()\n",
    "nb_tfidf.fit(Xt_train, yt_train)\n",
    "yt_pred = nb_tfidf.predict(Xt_test)\n",
    "\n",
    "print('Naive Bayes (TF-IDF)')\n",
    "print('Accuracy:', accuracy_score(yt_test, yt_pred))\n",
    "print('Confusion Matrix:\\n', confusion_matrix(yt_test, yt_pred))\n",
    "print('Classification Report:\\n', classification_report(yt_test, yt_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78e5cae",
   "metadata": {},
   "source": [
    "## 9. Model Training and Evaluation: Logistic Regression\n",
    "Train a Logistic Regression classifier and evaluate its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6a9a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression with CountVectorizer\n",
    "lr_count = LogisticRegression(max_iter=1000)\n",
    "lr_count.fit(Xc_train, yc_train)\n",
    "yc_pred_lr = lr_count.predict(Xc_test)\n",
    "\n",
    "print('Logistic Regression (CountVectorizer)')\n",
    "print('Accuracy:', accuracy_score(yc_test, yc_pred_lr))\n",
    "print('Confusion Matrix:\\n', confusion_matrix(yc_test, yc_pred_lr))\n",
    "print('Classification Report:\\n', classification_report(yc_test, yc_pred_lr))\n",
    "\n",
    "# Logistic Regression with TF-IDF\n",
    "lr_tfidf = LogisticRegression(max_iter=1000)\n",
    "lr_tfidf.fit(Xt_train, yt_train)\n",
    "yt_pred_lr = lr_tfidf.predict(Xt_test)\n",
    "\n",
    "print('Logistic Regression (TF-IDF)')\n",
    "print('Accuracy:', accuracy_score(yt_test, yt_pred_lr))\n",
    "print('Confusion Matrix:\\n', confusion_matrix(yt_test, yt_pred_lr))\n",
    "print('Classification Report:\\n', classification_report(yt_test, yt_pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b10ebc",
   "metadata": {},
   "source": [
    "## 10. Model Training and Evaluation: Support Vector Machine (Optional)\n",
    "Optionally, train a Support Vector Machine (SVM) classifier and evaluate its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613e7a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM with CountVectorizer\n",
    "svm_count = LinearSVC(max_iter=2000)\n",
    "svm_count.fit(Xc_train, yc_train)\n",
    "yc_pred_svm = svm_count.predict(Xc_test)\n",
    "\n",
    "print('SVM (CountVectorizer)')\n",
    "print('Accuracy:', accuracy_score(yc_test, yc_pred_svm))\n",
    "print('Confusion Matrix:\\n', confusion_matrix(yc_test, yc_pred_svm))\n",
    "print('Classification Report:\\n', classification_report(yc_test, yc_pred_svm))\n",
    "\n",
    "# SVM with TF-IDF\n",
    "svm_tfidf = LinearSVC(max_iter=2000)\n",
    "svm_tfidf.fit(Xt_train, yt_train)\n",
    "yt_pred_svm = svm_tfidf.predict(Xt_test)\n",
    "\n",
    "print('SVM (TF-IDF)')\n",
    "print('Accuracy:', accuracy_score(yt_test, yt_pred_svm))\n",
    "print('Confusion Matrix:\\n', confusion_matrix(yt_test, yt_pred_svm))\n",
    "print('Classification Report:\\n', classification_report(yt_test, yt_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648df19d",
   "metadata": {},
   "source": [
    "## 11. Compare CountVectorizer vs TF-IDF Results\n",
    "Compare the results (accuracy, confusion matrix, classification report) of models trained with CountVectorizer and TF-IDF features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c74edc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect accuracy scores for comparison\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['Naive Bayes', 'Logistic Regression', 'SVM'],\n",
    "    'CountVectorizer': [\n",
    "        accuracy_score(yc_test, nb_count.predict(Xc_test)),\n",
    "        accuracy_score(yc_test, lr_count.predict(Xc_test)),\n",
    "        accuracy_score(yc_test, svm_count.predict(Xc_test))\n",
    "    ],\n",
    "    'TF-IDF': [\n",
    "        accuracy_score(yt_test, nb_tfidf.predict(Xt_test)),\n",
    "        accuracy_score(yt_test, lr_tfidf.predict(Xt_test)),\n",
    "        accuracy_score(yt_test, svm_tfidf.predict(Xt_test))\n",
    "    ]\n",
    "})\n",
    "results.set_index('Model').plot(kind='bar', ylim=(0.9,1.0), title='Model Accuracy Comparison')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc00a93",
   "metadata": {},
   "source": [
    "## 12. Show Top Important Words for Each Class\n",
    "Display the most important words for each class based on model coefficients or feature importances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ba4cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_top_words(model, vectorizer, n=10):\n",
    "    feature_names = np.array(vectorizer.get_feature_names_out())\n",
    "    for i, class_label in enumerate(model.classes_):\n",
    "        if hasattr(model, 'coef_'):\n",
    "            top = np.argsort(model.coef_[i])[-n:]\n",
    "            print(f\"Top words for class '{class_label}' (coef):\", feature_names[top][::-1])\n",
    "        elif hasattr(model, 'feature_log_prob_'):\n",
    "            top = np.argsort(model.feature_log_prob_[i])[-n:]\n",
    "            print(f\"Top words for class '{class_label}' (log prob):\", feature_names[top][::-1])\n",
    "        print()\n",
    "\n",
    "print('Naive Bayes (CountVectorizer):')\n",
    "show_top_words(nb_count, count_vect)\n",
    "print('Logistic Regression (CountVectorizer):')\n",
    "show_top_words(lr_count, count_vect)\n",
    "print('Naive Bayes (TF-IDF):')\n",
    "show_top_words(nb_tfidf, tfidf_vect)\n",
    "print('Logistic Regression (TF-IDF):')\n",
    "show_top_words(lr_tfidf, tfidf_vect)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

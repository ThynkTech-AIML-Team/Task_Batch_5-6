{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c95929e-8fe9-4198-86d1-4f71053047f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    words = text.split()\n",
    "    words = [w for w in words if w not in stop_words]\n",
    "    return \" \".join(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3688ffd7-e20e-41fc-9344-f3ecd390728f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6310e8e4-67cd-4921-8580-adc25643de55",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "\"text\": [\n",
    "\"Government passes new healthcare bill\",\n",
    "\"Aliens landed in New York yesterday\",\n",
    "\"Stock market hits record high\",\n",
    "\"Fake cure for cancer discovered\",\n",
    "\"Scientists discover new species\",\n",
    "\"NASA launches new satellite\",\n",
    "\"Celebrity adopts alien baby\",\n",
    "\"New education reform introduced\",\n",
    "\"Secret time travel machine found\",\n",
    "\"Doctors develop new vaccine\"\n",
    "],\n",
    "\"label\": [1,0,1,0,1,1,0,1,0,1]\n",
    "}\n",
    "\n",
    "df_fake = pd.DataFrame(data)\n",
    "df_fake[\"clean\"] = df_fake[\"text\"].apply(clean_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7d1bbab5-6476-4baf-b867-dbe813ebd87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF + Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "43eeb79a-9393-42db-984d-c47121f8831c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Confusion Matrix:\n",
      " [[4 0]\n",
      " [0 6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         4\n",
      "           1       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           1.00        10\n",
      "   macro avg       1.00      1.00      1.00        10\n",
      "weighted avg       1.00      1.00      1.00        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df_fake[\"clean\"]\n",
    "y = df_fake[\"label\"]\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_vec = vectorizer.fit_transform(X)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_vec, y)\n",
    "\n",
    "y_pred = model.predict(X_vec)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y, y_pred))\n",
    "print(classification_report(y, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "769c9c8b-2521-4e79-90e1-62be4f9e4bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top Important Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8638970-a31c-49ca-8ae0-07f6633afbaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Important words for Real News:\n",
      "['reform', 'satellite', 'vaccine', 'species', 'new']\n"
     ]
    }
   ],
   "source": [
    "feature_names = vectorizer.get_feature_names_out()\n",
    "coefs = model.coef_[0]\n",
    "\n",
    "top_words = np.argsort(coefs)[-5:]\n",
    "print(\"Important words for Real News:\")\n",
    "print([feature_names[i] for i in top_words])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e354f87e-f495-48c8-896d-b96d9133a84a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3378f9cf-d71f-4c8b-89e4-61c42688a475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: spacy in C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages (3.8.11)\n",
      "Requirement already satisfied: emoji in C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages (2.15.0)\n",
      "Requirement already satisfied: click in C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages (from nltk) (8.3.1)\n",
      "Requirement already satisfied: joblib in C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages (from nltk) (1.5.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages (from nltk) (2026.1.15)\n",
      "Requirement already satisfied: tqdm in C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages (from spacy) (1.0.15)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages (from spacy) (2.0.13)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages (from spacy) (8.3.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages (from spacy) (2.5.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages (from spacy) (0.4.3)\n",
      "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages (from spacy) (0.24.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages (from spacy) (2.3.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages (from spacy) (2.32.5)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages (from spacy) (2.12.5)\n",
      "Requirement already satisfied: jinja2 in C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages (from spacy) (3.1.6)\n",
      "Requirement already satisfied: setuptools in C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages (from spacy) (65.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages (from spacy) (26.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.41.5)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2026.1.4)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.3)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: colorama in C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages (from tqdm->nltk) (0.4.6)\n",
      "Requirement already satisfied: typer>=0.24.0 in C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages (from typer-slim<1.0.0,>=0.3.0->spacy) (0.24.0)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages (from weasel<0.5.0,>=0.4.2->spacy) (0.23.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages (from weasel<0.5.0,>=0.4.2->spacy) (7.5.0)\n",
      "Requirement already satisfied: wrapt in C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy) (2.1.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages (from typer>=0.24.0->typer-slim<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=12.3.0 in C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages (from typer>=0.24.0->typer-slim<1.0.0,>=0.3.0->spacy) (14.3.2)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages (from typer>=0.24.0->typer-slim<1.0.0,>=0.3.0->spacy) (0.0.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim<1.0.0,>=0.3.0->spacy) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim<1.0.0,>=0.3.0->spacy) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages (from markdown-it-py>=2.2.0->rich>=12.3.0->typer>=0.24.0->typer-slim<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages (from jinja2->spacy) (3.0.3)\n",
      "Collecting en-core-web-sm==3.8.0\n",
      "  Using cached https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk spacy emoji\n",
    "!python -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcb8800-aa64-4f61-a5b9-0bfc40103efe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "327e3ca9-bbd5-400d-9c79-e782221e62f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "import re\n",
    "import emoji\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42eb6868-c1a7-4fd9-ac25-645af1e5a5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A. Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22c322df-29b3-40b4-88b7-3b9c53dda6e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK Tokens:\n",
      "['Natural', 'Language', 'Processing', 'is', 'amazing', '!', 'It', 'helps', 'computers', 'understand', 'human', 'language', '.']\n",
      "\n",
      "spaCy Tokens:\n",
      "['Natural', 'Language', 'Processing', 'is', 'amazing', '!', 'It', 'helps', 'computers', 'understand', 'human', 'language', '.']\n"
     ]
    }
   ],
   "source": [
    "text = \"Natural Language Processing is amazing! It helps computers understand human language.\"\n",
    "\n",
    "# NLTK Tokenizer\n",
    "nltk_tokens = word_tokenize(text)\n",
    "\n",
    "# spaCy Tokenizer\n",
    "doc = nlp(text)\n",
    "spacy_tokens = [token.text for token in doc]\n",
    "\n",
    "print(\"NLTK Tokens:\")\n",
    "print(nltk_tokens)\n",
    "\n",
    "print(\"\\nspaCy Tokens:\")\n",
    "print(spacy_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b88d4d-e8fa-4935-a391-e224b6aa3be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B. Stopwords Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4877aa0a-0a61-4cd2-a934-929342cd77c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Removing Stopwords:\n",
      "['This', 'is', 'a', 'simple', 'example', 'showing', 'how', 'stopwords', 'are', 'removed', 'from', 'a', 'sentence', '.']\n",
      "\n",
      "After Removing Stopwords:\n",
      "['simple', 'example', 'showing', 'stopwords', 'removed', 'sentence', '.']\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "text = \"This is a simple example showing how stopwords are removed from a sentence.\"\n",
    "\n",
    "tokens = word_tokenize(text)\n",
    "\n",
    "filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
    "\n",
    "print(\"Before Removing Stopwords:\")\n",
    "print(tokens)\n",
    "\n",
    "print(\"\\nAfter Removing Stopwords:\")\n",
    "print(filtered_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50184349-2718-490a-988c-742bd510225e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C. Lemmatization & Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3cb57a9e-cccd-4269-a62a-9c311323a024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Words: ['studies', 'studying', 'studied', 'easily', 'flying', 'flies']\n",
      "After Stemming: ['studi', 'studi', 'studi', 'easili', 'fli', 'fli']\n",
      "After Lemmatization: ['study', 'studying', 'studied', 'easily', 'flying', 'fly']\n"
     ]
    }
   ],
   "source": [
    "text = \"studies studying studied easily flying flies\"\n",
    "\n",
    "tokens = word_tokenize(text)\n",
    "\n",
    "# Stemming\n",
    "stemmer = PorterStemmer()\n",
    "stemmed = [stemmer.stem(word) for word in tokens]\n",
    "\n",
    "# Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "print(\"Original Words:\", tokens)\n",
    "print(\"After Stemming:\", stemmed)\n",
    "print(\"After Lemmatization:\", lemmatized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3e243b-0181-4e84-ab00-94e4594c2489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# D. Handling Punctuation, Special Characters, Emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8979d905-4254-4b03-a3df-96803477fd86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text:\n",
      "Hello!!! This is awesome ðŸ˜Š #NLP @user123 Let's learn!!!\n",
      "\n",
      "Cleaned Text:\n",
      "Hello This is awesome    Lets learn\n"
     ]
    }
   ],
   "source": [
    "text = \"Hello!!! This is awesome ðŸ˜Š #NLP @user123 Let's learn!!!\"\n",
    "\n",
    "# Remove emojis\n",
    "text_no_emoji = emoji.replace_emoji(text, replace='')\n",
    "\n",
    "# Remove hashtags, mentions, punctuation\n",
    "clean_text = re.sub(r'[@#]\\w+', '', text_no_emoji)\n",
    "clean_text = re.sub(r'[^\\w\\s]', '', clean_text)\n",
    "\n",
    "print(\"Original Text:\")\n",
    "print(text)\n",
    "\n",
    "print(\"\\nCleaned Text:\")\n",
    "print(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b99728a-1c40-499c-9604-c1e9d5790f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# E. Lowercasing & Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d379597-cde7-479c-aade-2b5a62d24d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:   This   Is    A   MIXED Case   Sentence.   \n",
      "Normalized: this is a mixed case sentence.\n"
     ]
    }
   ],
   "source": [
    "text = \"  This   Is    A   MIXED Case   Sentence.   \"\n",
    "\n",
    "# Lowercase\n",
    "text_lower = text.lower()\n",
    "\n",
    "# Normalize spaces\n",
    "normalized = re.sub(r'\\s+', ' ', text_lower).strip()\n",
    "\n",
    "print(\"Original:\", text)\n",
    "print(\"Normalized:\", normalized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6a5722-62ea-4633-95c8-cee71dc706dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# F. Regex for Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3b669ed-643e-430b-8fd7-770d58a19569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Emails: ['support@gmail.com', 'admin123@yahoo.com.']\n",
      "\n",
      "Text Without Numbers: Contact us at support@gmail.com or admin@yahoo.com. Call  today!\n",
      "\n",
      "Text With Clean Spaces: Contact us at support@gmail.com or admin@yahoo.com. Call today!\n"
     ]
    }
   ],
   "source": [
    "text = \"Contact us at support@gmail.com or admin123@yahoo.com. Call 123456 today!\"\n",
    "\n",
    "# Extract emails\n",
    "emails = re.findall(r'\\S+@\\S+', text)\n",
    "\n",
    "# Remove numbers\n",
    "no_numbers = re.sub(r'\\d+', '', text)\n",
    "\n",
    "# Replace multiple spaces with one\n",
    "clean_spaces = re.sub(r'\\s+', ' ', no_numbers)\n",
    "\n",
    "print(\"Extracted Emails:\", emails)\n",
    "print(\"\\nText Without Numbers:\", no_numbers)\n",
    "print(\"\\nText With Clean Spaces:\", clean_spaces)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d24c49e-da87-485d-8fdc-6e3627fb25f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

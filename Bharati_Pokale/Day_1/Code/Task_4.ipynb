{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d292ff1-3a82-4131-844b-e0b122ea6d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages (1.8.0)\n",
      "Requirement already satisfied: numpy>=1.24.1 in C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages (from scikit-learn) (2.3.5)\n",
      "Requirement already satisfied: scipy>=1.10.0 in C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages (from scikit-learn) (1.17.0)\n",
      "Requirement already satisfied: joblib>=1.3.0 in C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages (from scikit-learn) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages (from scikit-learn) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6954b93e-72c9-4e30-8ac9-82b9ea301895",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b6645d7-7a7c-4fda-b8bc-3412bb40ffa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"Natural Language Processing is amazing\",\n",
    "    \"I love learning NLP and machine learning\",\n",
    "    \"NLP helps computers understand human language\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42b41c4b-8639-4cf4-b087-184957f91096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag-of-Words Matrix:\n",
      "\n",
      "   amazing  and  computers  helps  human  is  language  learning  love  \\\n",
      "0        1    0          0      0      0   1         1         0     0   \n",
      "1        0    1          0      0      0   0         0         2     1   \n",
      "2        0    0          1      1      1   0         1         0     0   \n",
      "\n",
      "   machine  natural  nlp  processing  understand  \n",
      "0        0        1    0           1           0  \n",
      "1        1        0    1           0           0  \n",
      "2        0        0    1           0           1  \n"
     ]
    }
   ],
   "source": [
    "# Create BoW vectorizer\n",
    "bow_vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform sentences\n",
    "bow_matrix = bow_vectorizer.fit_transform(sentences)\n",
    "\n",
    "# Convert to DataFrame for easy visualization\n",
    "bow_df = pd.DataFrame(bow_matrix.toarray(), columns=bow_vectorizer.get_feature_names_out())\n",
    "\n",
    "print(\"Bag-of-Words Matrix:\\n\")\n",
    "print(bow_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0dc21e61-eafb-4fdc-b7f2-82f41296dc39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TF-IDF Matrix:\n",
      "\n",
      "    amazing       and  computers     helps     human        is  language  \\\n",
      "0  0.467351  0.000000   0.000000  0.000000  0.000000  0.467351  0.355432   \n",
      "1  0.000000  0.363255   0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "2  0.000000  0.000000   0.440362  0.440362  0.440362  0.000000  0.334907   \n",
      "\n",
      "   learning      love   machine   natural       nlp  processing  understand  \n",
      "0  0.000000  0.000000  0.000000  0.467351  0.000000    0.467351    0.000000  \n",
      "1  0.726509  0.363255  0.363255  0.000000  0.276265    0.000000    0.000000  \n",
      "2  0.000000  0.000000  0.000000  0.000000  0.334907    0.000000    0.440362  \n"
     ]
    }
   ],
   "source": [
    "# Create TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform sentences\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(sentences)\n",
    "\n",
    "# Convert to DataFrame\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "print(\"\\nTF-IDF Matrix:\\n\")\n",
    "print(tfidf_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b977cf0d-e416-4f6d-bdd2-c1ae89a42e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Word 'nlp' Importance:\n",
      "BoW counts: [0, 1, 1]\n",
      "TF-IDF scores: [0.0, 0.2762645695949752, 0.3349067026613031]\n"
     ]
    }
   ],
   "source": [
    "# Example: compare BoW vs TF-IDF for the word 'nlp'\n",
    "word = 'nlp'\n",
    "\n",
    "bow_scores = bow_df[word] if word in bow_df.columns else None\n",
    "tfidf_scores = tfidf_df[word] if word in tfidf_df.columns else None\n",
    "\n",
    "print(f\"\\nWord '{word}' Importance:\")\n",
    "print(\"BoW counts:\", bow_scores.tolist() if bow_scores is not None else \"Not in vocab\")\n",
    "print(\"TF-IDF scores:\", tfidf_scores.tolist() if tfidf_scores is not None else \"Not in vocab\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57882cd-f9e4-49e1-9c59-4ebcf0569a6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8448114",
   "metadata": {},
   "source": [
    "**Name : Atharva Hanumant Admile**\n",
    "\n",
    "Batch no: 06"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4830c77",
   "metadata": {},
   "source": [
    "**1. Basic Text Classification Project**\n",
    "\n",
    "Objective: Build a simple text classification model and compare 2â€“3 algorithms.\n",
    "\n",
    "Dataset:\n",
    "\n",
    "- SMS Spam Collection Dataset\n",
    "\n",
    "Steps:\n",
    "1. Text Cleaning (lowercase, remove punctuation)\n",
    "\n",
    "2. Remove stopwords\n",
    "\n",
    "3. Convert text using CountVectorizer and TF-IDF\n",
    "\n",
    "Models to Use:\n",
    "\n",
    "- Naive Bayes\n",
    "\n",
    "- Logistic Regression\n",
    "\n",
    "- Support Vector Machine (Optional)\n",
    "\n",
    "Evaluation:\n",
    "\n",
    "- Accuracy\n",
    "\n",
    "- Confusion Matrix\n",
    "\n",
    "- Classification Report\n",
    "Bonus:\n",
    "- Compare CountVectorizer vs TF-IDF results\n",
    "- Show top important words for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4f6ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load dataset\n",
    "url = 'https://raw.githubusercontent.com/mohitgupta-omg/Kaggle-SMS-Spam-Collection-Dataset-/master/spam.csv'\n",
    "df = pd.read_csv(url, encoding='latin-1')\n",
    "df = df[['v1', 'v2']]\n",
    "df.columns = ['label', 'text']\n",
    "df['label'] = df['label'].map({'ham': 0, 'spam': 1})\n",
    "\n",
    "# Text cleaning\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = ''.join([char for char in text if char not in string.punctuation])\n",
    "    words = text.split()\n",
    "    words = [word for word in words if word not in stopwords.words('english')]\n",
    "    return ' '.join(words)\n",
    "\n",
    "df['clean_text'] = df['text'].apply(clean_text)\n",
    "\n",
    "# Split data\n",
    "X = df['clean_text']\n",
    "y = df['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Function to train and evaluate\n",
    "def train_evaluate(vectorizer, model, name, vec_name):\n",
    "    X_train_vec = vectorizer.fit_transform(X_train)\n",
    "    X_test_vec = vectorizer.transform(X_test)\n",
    "    model.fit(X_train_vec, y_train)\n",
    "    y_pred = model.predict(X_test_vec)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"{name} with {vec_name} - Accuracy: {acc:.4f}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f\"Confusion Matrix: {name} with {vec_name}\")\n",
    "    plt.show()\n",
    "    return acc, vectorizer, model\n",
    "\n",
    "# Vectorizers\n",
    "count_vec = CountVectorizer()\n",
    "tfidf_vec = TfidfVectorizer()\n",
    "\n",
    "# Models\n",
    "nb = MultinomialNB()\n",
    "lr = LogisticRegression()\n",
    "svm = SVC(kernel='linear')  # Optional\n",
    "\n",
    "# Evaluate with CountVectorizer\n",
    "print(\"Using CountVectorizer:\")\n",
    "acc_nb_count, count_vec, nb_count = train_evaluate(count_vec, nb, \"Naive Bayes\", \"Count\")\n",
    "acc_lr_count, _, lr_count = train_evaluate(count_vec, lr, \"Logistic Regression\", \"Count\")\n",
    "acc_svm_count, _, svm_count = train_evaluate(count_vec, svm, \"SVM\", \"Count\")\n",
    "\n",
    "# Evaluate with TF-IDF\n",
    "print(\"\\nUsing TF-IDF:\")\n",
    "acc_nb_tfidf, tfidf_vec, nb_tfidf = train_evaluate(tfidf_vec, nb, \"Naive Bayes\", \"TF-IDF\")\n",
    "acc_lr_tfidf, _, lr_tfidf = train_evaluate(tfidf_vec, lr, \"Logistic Regression\", \"TF-IDF\")\n",
    "acc_svm_tfidf, _, svm_tfidf = train_evaluate(tfidf_vec, svm, \"SVM\", \"TF-IDF\")\n",
    "\n",
    "# Bonus: Compare vectorizers\n",
    "data = {\n",
    "    'Model': ['Naive Bayes', 'Logistic Regression', 'SVM'],\n",
    "    'CountVectorizer Accuracy': [acc_nb_count, acc_lr_count, acc_svm_count],\n",
    "    'TF-IDF Accuracy': [acc_nb_tfidf, acc_lr_tfidf, acc_svm_tfidf]\n",
    "}\n",
    "comparison_df = pd.DataFrame(data)\n",
    "print(\"\\nComparison:\")\n",
    "print(comparison_df)\n",
    "\n",
    "# Bonus: Top important words for each class (using Logistic Regression with TF-IDF)\n",
    "feature_names = tfidf_vec.get_feature_names_out()\n",
    "coef = lr_tfidf.coef_[0]\n",
    "top_spam = [feature_names[i] for i in coef.argsort()[-10:][::-1]]\n",
    "top_ham = [feature_names[i] for i in coef.argsort()[:10]]\n",
    "print(\"\\nTop words for Spam:\", top_spam)\n",
    "print(\"Top words for Ham:\", top_ham)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec9d8c9c",
   "metadata": {},
   "source": [
    "**Name : Atharva Hanumant Admile**\n",
    "\n",
    "Batch no: 06"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bd1b17",
   "metadata": {},
   "source": [
    "**2. Word Embedding Mini Task**\n",
    "\n",
    "Objective: Understand basic word embeddings.\n",
    "\n",
    "Tasks:\n",
    "\n",
    "- Load pretrained Word2Vec or GloVe\n",
    "\n",
    "- Find similar words (example: king → ?)\n",
    "\n",
    "- Perform basic analogy (king - man + woman)\n",
    "\n",
    "- Visualize 10–20 words using PCA (2D plot)\n",
    "\n",
    "Bonus:\n",
    "\n",
    "- Compare Word2Vec vs GloVe similarity results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e087d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load models\n",
    "glove = api.load('glove-wiki-gigaword-50')  # Small for speed\n",
    "word2vec = api.load('word2vec-google-news-300')\n",
    "\n",
    "# Similar words\n",
    "word = 'king'\n",
    "print(\"GloVe similar to 'king':\", glove.most_similar(word, topn=5))\n",
    "print(\"Word2Vec similar to 'king':\", word2vec.most_similar(word, topn=5))\n",
    "\n",
    "# Analogy\n",
    "analogy_glove = glove.most_similar(positive=['king', 'woman'], negative=['man'], topn=1)\n",
    "print(\"GloVe analogy: king - man + woman ≈\", analogy_glove[0][0])\n",
    "analogy_w2v = word2vec.most_similar(positive=['king', 'woman'], negative=['man'], topn=1)\n",
    "print(\"Word2Vec analogy: king - man + woman ≈\", analogy_w2v[0][0])\n",
    "\n",
    "# Visualization with PCA\n",
    "words = ['king', 'queen', 'man', 'woman', 'boy', 'girl', 'apple', 'banana', 'car', 'bike', 'paris', 'france', 'london', 'england', 'cat', 'dog', 'happy', 'sad', 'run', 'jump']\n",
    "embeddings = np.array([glove[w] for w in words if w in glove])\n",
    "pca = PCA(n_components=2)\n",
    "embeddings_2d = pca.fit_transform(embeddings)\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1])\n",
    "for i, word in enumerate([w for w in words if w in glove]):\n",
    "    plt.annotate(word, (embeddings_2d[i, 0], embeddings_2d[i, 1]))\n",
    "plt.title('PCA Visualization of GloVe Embeddings')\n",
    "plt.show()\n",
    "\n",
    "# Bonus: Comparison\n",
    "print(\"\\nSimilarity Comparison (cosine similarity for 'king' and 'queen'):\")\n",
    "print(\"GloVe:\", glove.similarity('king', 'queen'))\n",
    "print(\"Word2Vec:\", word2vec.similarity('king', 'queen'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d8aed6",
   "metadata": {},
   "source": [
    "GloVe similar to 'king': [('prince', 0.8236179351806641), ('queen', 0.7839043140411377), ('ii', 0.7746230363845825), ('emperor', 0.7736247777938843), ('son', 0.766719400882721)]\n",
    "Word2Vec similar to 'king': [('kings', 0.7138045430183411), ('queen', 0.6510956883430481), ('monarch', 0.6413194537162781), ('crown_prince', 0.6204220056533813), ('prince', 0.6159993410110474)]\n",
    "GloVe analogy: king - man + woman ≈ queen\n",
    "Word2Vec analogy: king - man + woman ≈ queen\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
